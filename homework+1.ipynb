{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Homework 1 CSCE 470\n",
    "#2-20-2017\n",
    "#By: Rodrigo Gomez-Palacio\n",
    "\n",
    "\t#*-------------Note---------------*#\n",
    "\t#Jupyter notebook (visual) outputs\n",
    "\t#can be found at\n",
    "\t#https://github.com/rgomezp/info_storage_and_retrieval\n",
    "\t#*--------------------------------*#\n",
    "\n",
    "#Imports and Inputs\n",
    "import nltk\n",
    "#nltk.download()                          #downloads all nltk packages\n",
    "import string\n",
    "import math\n",
    "\n",
    "documents = [\n",
    "    \"Today the aggies won! Go aggies!\", \n",
    "    \"aggies have won today\", \n",
    "    \"the aggies lost last week\", \n",
    "    \"Find the latest Aggies news\", \n",
    "    \"An Aggie is a student at Texas A&M\"\n",
    "]\n",
    "\n",
    "documents2 = documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Punctuation removal \n",
    "temp = []\n",
    "for doc in documents:\n",
    "    tokens = doc.translate(None,string.punctuation)\n",
    "    temp.append(tokens)\n",
    "    \n",
    "documents = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Tokenize\n",
    "temp = []\n",
    "for doc in documents:\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    temp.append(tokens)\n",
    "    \n",
    "documents = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Case Folding\n",
    "for doc in documents:\n",
    "    for term in range(0,len(doc)):\n",
    "        doc[term] = doc[term].lower()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Stopword removal\n",
    "#stopwords from nltk 'corpus' found here: http://www.nltk.org/book/ch02.html\n",
    "stop = set(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now'])\n",
    "\n",
    "for doc in range(0,len(documents)):\n",
    "    new_doc = []\n",
    "    for term in range(0,len(documents[doc])):\n",
    "        if documents[doc][term] not in stop:\n",
    "        #if term is not in stop set, keep\n",
    "            new_doc.append(documents[doc][term])\n",
    "    documents[doc] = new_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Lemmatization using Wordnet Lemmatizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "for doc in documents:\n",
    "    for term in range(0,len(doc)):\n",
    "            doc[term] = lmtzr.lemmatize(doc[term])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Preprocessing Output---\n",
      "['today', u'aggi', 'won', 'go', u'aggi']\n",
      "[u'aggi', 'won', 'today']\n",
      "[u'aggi', 'lost', 'last', 'week']\n",
      "['find', 'latest', u'aggi', u'news']\n",
      "[u'aggi', 'student', u'texa']\n"
     ]
    }
   ],
   "source": [
    "#Stemming with Porter Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for doc in documents:\n",
    "    for term in range(0,len(doc)):\n",
    "            doc[term] = stemmer.stem(doc[term])\n",
    "\n",
    "print \"---Preprocessing Output---\"\n",
    "for i in documents:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Incidence matrix---\n",
      "[1, 1, 1, 1, 1]\n",
      "[0, 0, 0, 1, 0]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 1, 0]\n",
      "[0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 1]\n",
      "[1, 1, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0]\n",
      "[1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#Build  Term-Document Incidence Matrix\n",
    "\n",
    "#Build set with unique terms\n",
    "terms = []\n",
    "for doc in documents:\n",
    "    for term in doc:\n",
    "        if term not in terms:\n",
    "            terms.append(term)\n",
    "terms.sort()\n",
    "            \n",
    "incidence_matrix = []          #cols: documents,  rows: terms\n",
    "\n",
    "for term in terms:\n",
    "    row = []\n",
    "    for doc in documents:\n",
    "    #if term appears in document: true...else: false\n",
    "        if term in doc:      \n",
    "            row.append(1)\n",
    "        else:\n",
    "            row.append(0)\n",
    "    incidence_matrix.append(row)\n",
    "\n",
    "print \"---Incidence matrix---\"\n",
    "for i in incidence_matrix:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Count_matrix:---\n",
      "[2, 1, 1, 1, 1]\n",
      "[0, 0, 0, 1, 0]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 1, 0]\n",
      "[0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 1]\n",
      "[1, 1, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0]\n",
      "[1, 1, 0, 0, 0]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Build term-document count matrix (tf_td)\n",
    "\n",
    "count_matrix = []    \n",
    "\n",
    "for term in terms:\n",
    "    row = []\n",
    "    for doc in documents:\n",
    "        count = 0\n",
    "        if term in doc:\n",
    "            for index in range(0,len(doc)):\n",
    "                if doc[index] == term:\n",
    "                    count+=1\n",
    "            row.append(count)\n",
    "        else:\n",
    "            row.append(0)\n",
    "    count_matrix.append(row)\n",
    "print \"---Count_matrix:---\"\n",
    "for i in count_matrix:\n",
    "    print i\n",
    "    \n",
    "print count_matrix[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc_frequency_vector:\n",
      "[5, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2] \n",
      "\n",
      "\n",
      "Idf_vector:\n",
      "0.0\n",
      "0.698970004336\n",
      "0.698970004336\n",
      "0.698970004336\n",
      "0.698970004336\n",
      "0.698970004336\n",
      "0.698970004336\n",
      "0.698970004336\n",
      "0.698970004336\n",
      "0.397940008672\n",
      "0.698970004336\n",
      "0.397940008672\n"
     ]
    }
   ],
   "source": [
    "#Build document frequency vector\n",
    "document_freq_vec = []\n",
    "for i in range(0,len(terms)):\n",
    "    count = 0\n",
    "    for doc in documents:\n",
    "        if terms[i] in doc:\n",
    "            count+=1\n",
    "    document_freq_vec.append(count)\n",
    "    \n",
    "print \"Doc_frequency_vector:\\n\", document_freq_vec, \"\\n\\n\"\n",
    "\n",
    "#Build idf vector\n",
    "N = float(len(documents))\n",
    "idf_vec = []\n",
    "for num in document_freq_vec:\n",
    "    weight = math.log10(N/num)\n",
    "    idf_vec.append(weight)\n",
    "    \n",
    "print \"Idf_vector:\"\n",
    "for i in idf_vec:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Tf_idf_matrix---\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.21041, 0.0]\n",
      "[0.21041, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.21041, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.21041, 0.0]\n",
      "[0.0, 0.0, 0.21041, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.21041, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.21041]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.21041]\n",
      "[0.11979, 0.11979, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.21041, 0.0, 0.0]\n",
      "[0.11979, 0.11979, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "#Build Tf-Idf Matrix\n",
    "tf_idf_matrix = []\n",
    "\n",
    "for term in range(0,len(terms)):\n",
    "    row = []\n",
    "    for doc in range(0,len(documents)):\n",
    "        weight = math.log10(1.0+float(count_matrix[term][doc]))*idf_vec[term]\n",
    "        row.append(round(weight,5))\n",
    "    tf_idf_matrix.append(row)\n",
    "    \n",
    "print \"---Tf_idf_matrix---\" \n",
    "for i in tf_idf_matrix:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Log-Frequency Matrix\n",
    "log_freq_matrix = []\n",
    "for term_vec in count_matrix:\n",
    "    row = []\n",
    "    for i in range(0,len(term_vec)):\n",
    "        temp = math.log10(1+term_vec[i])\n",
    "        row.append(temp)\n",
    "    log_freq_matrix.append(row)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Transpose log_freq_matrix\n",
    "log_freq_matrix = zip(*log_freq_matrix)\n",
    "\n",
    "normalized_lfm = []                #normalized log_freq_matrix\n",
    "#Length Normalization\n",
    "for doc_vec in log_freq_matrix:\n",
    "    #Calculate denominator\n",
    "    sum_of_squares = 0\n",
    "    for num in doc_vec:\n",
    "        sum_of_squares += num**2\n",
    "    denominator = math.sqrt(sum_of_squares)\n",
    "    new_vec = []\n",
    "    for num in doc_vec:\n",
    "        norm_val = num / denominator\n",
    "        new_vec.append(norm_val)\n",
    "    normalized_lfm.append(new_vec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Cosine Similarity Matrix---\n",
      "1 [1, 0.882, 0.338, 0.338, 0.39]\n",
      "2 [0.882, 1, 0.289, 0.289, 0.333]\n",
      "3 [0.338, 0.289, 1, 0.25, 0.289]\n",
      "4 [0.338, 0.289, 0.25, 1, 0.289]\n",
      "5 [0.39, 0.333, 0.289, 0.289, 1]\n",
      "\n",
      "Documents\n",
      "1 : Today the aggies won! Go aggies!\n",
      "2 : aggies have won today\n",
      "3 : the aggies lost last week\n",
      "4 : Find the latest Aggies news\n",
      "5 : An Aggie is a student at Texas A&M\n"
     ]
    }
   ],
   "source": [
    "#Build 5 x 5 cosine similarity matrix\n",
    "cosine_sim = []\n",
    "\n",
    "for doc_vec1 in range(0,len(normalized_lfm)):\n",
    "    row = []\n",
    "    for doc_vec2 in range(0,len(normalized_lfm)):\n",
    "        if doc_vec1 == doc_vec2:\n",
    "            row.append(1)\n",
    "        elif doc_vec1 < doc_vec2:                            #symmetric matrix, don't waste operations on half the mtrx\n",
    "            score = 0\n",
    "            for i in range(0,len(normalized_lfm[doc_vec1])):\n",
    "                score += (normalized_lfm[doc_vec1][i]*normalized_lfm[doc_vec2][i])\n",
    "            row.append(round(score,3))\n",
    "        else:\n",
    "            row.append(0)\n",
    "    cosine_sim.append(row)\n",
    "    \n",
    "#Because symmetric matrix, copy over\n",
    "for doc_vec1 in range(0,len(normalized_lfm)):\n",
    "    for doc_vec2 in range(0,len(normalized_lfm)):\n",
    "        if doc_vec1 > doc_vec2:\n",
    "            cosine_sim[doc_vec1][doc_vec2] = cosine_sim[doc_vec2][doc_vec1]\n",
    "\n",
    "print \"---Cosine Similarity Matrix---\"\n",
    "for row in range(0,len(cosine_sim)):\n",
    "    print row+1,cosine_sim[row]\n",
    "print \"\\nDocuments\"\n",
    "for doc in range(0,len(documents2)):\n",
    "    print doc+1,\":\", documents2[doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Part 2------------(OPTIONAL)\n",
    "#Linked List Class\n",
    "class Node:\n",
    "    def __init__(self,initdata):\n",
    "        self.data = initdata\n",
    "        self.next = None\n",
    "\n",
    "    def getData(self):\n",
    "        return self.data\n",
    "\n",
    "    def getNext(self):\n",
    "        return self.next\n",
    "\n",
    "    def setData(self,newdata):\n",
    "        self.data = newdata\n",
    "\n",
    "    def setNext(self,newnext):\n",
    "        self.next = newnext\n",
    "        \n",
    "#Term & Frequency Class\n",
    "class Term:\n",
    "    def __init__(self,initterm,initfreq):\n",
    "        self.term = initterm\n",
    "        self.freq = initfreq\n",
    "        \n",
    "#Build Inverted Index\n",
    "head_container = []\n",
    "\n",
    "\n",
    "\n",
    "for row in range(0,len(incidence_matrix)):\n",
    "    count = 0\n",
    "    for i in incidence_matrix[row]:\n",
    "        count += i\n",
    "    term_data = Term(terms[row],count)   #put term and count into struct\n",
    "    node = Node(term_data)               #put struct into node\n",
    "    head_container.append(node)          #put node into head_container\n",
    "    for j in range(0,len(incidence_matrix[row])):\n",
    "        if incidence_matrix[row][j]==1:\n",
    "            temp_node = Node(j)\n",
    "            node.next=temp_node\n",
    "            node = node.next\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ aggi 5 ] -> 0 -> 1 -> 2 -> 3 -> 4 -> //\n",
      "\n",
      "[ find 1 ] -> 3 -> //\n",
      "\n",
      "[ go 1 ] -> 0 -> //\n",
      "\n",
      "[ last 1 ] -> 2 -> //\n",
      "\n",
      "[ latest 1 ] -> 3 -> //\n",
      "\n",
      "[ lost 1 ] -> 2 -> //\n",
      "\n",
      "[ news 1 ] -> 3 -> //\n",
      "\n",
      "[ student 1 ] -> 4 -> //\n",
      "\n",
      "[ texa 1 ] -> 4 -> //\n",
      "\n",
      "[ today 2 ] -> 0 -> 1 -> //\n",
      "\n",
      "[ week 1 ] -> 2 -> //\n",
      "\n",
      "[ won 2 ] -> 0 -> 1 -> //\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in head_container:\n",
    "    print \"[\", i.data.term, i.data.freq,\"] ->\",\n",
    "    node = i.next\n",
    "    while node is not None:\n",
    "        print node.data,\"->\",\n",
    "        node = node.next\n",
    "    print \"//\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
