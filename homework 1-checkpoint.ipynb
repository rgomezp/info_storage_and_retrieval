{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Imports and Inputs\n",
    "import nltk\n",
    "#nltk.download()                          #downloads all nltk packages\n",
    "import string\n",
    "import math\n",
    "\n",
    "documents = [\"Today the aggies won! Go aggies!\", \"aggies have won today\", \"the aggies lost last week\", \"Find the latest Aggies news\", \"An Aggie is a student at Texas A&M\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Punctuation removal \n",
    "temp = []\n",
    "for doc in documents:\n",
    "    tokens = doc.translate(None,string.punctuation)\n",
    "    temp.append(tokens)\n",
    "    \n",
    "documents = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Tokenize\n",
    "temp = []\n",
    "for doc in documents:\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    temp.append(tokens)\n",
    "    \n",
    "documents = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Case Folding\n",
    "for doc in documents:\n",
    "    for term in range(0,len(doc)):\n",
    "        doc[term] = doc[term].lower()\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Stopword removal\n",
    "from nltk.corpus import stopwords\n",
    "stop = set([\"the\",\"go\",\"have\",\"an\",\"is\",\"a\",\"at\"])\n",
    "\n",
    "for doc in range(0,len(documents)):\n",
    "    new_doc = []\n",
    "    for term in range(0,len(documents[doc])):\n",
    "        if documents[doc][term] not in stop:\n",
    "            new_doc.append(documents[doc][term])\n",
    "    documents[doc] = new_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "for doc in documents:\n",
    "    for term in range(0,len(doc)):\n",
    "            doc[term] = lmtzr.lemmatize(doc[term])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Preprocessing Output---\n",
      "['today', u'aggi', 'won', u'aggi']\n",
      "[u'aggi', 'won', 'today']\n",
      "[u'aggi', 'lost', 'last', 'week']\n",
      "['find', 'latest', u'aggi', u'news']\n",
      "[u'aggi', 'student', u'texa', 'am']\n"
     ]
    }
   ],
   "source": [
    "#Stemming with Porter Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for doc in documents:\n",
    "    for term in range(0,len(doc)):\n",
    "            doc[term] = stemmer.stem(doc[term])\n",
    "\n",
    "print \"---Preprocessing Output---\"\n",
    "for i in documents:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Incidence matrix---\n",
      "[0, 0, 1, 0, 0]\n",
      "[0, 0, 1, 0, 0]\n",
      "[0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 1, 0]\n",
      "[1, 1, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "#Build  term-document incidence matrix\n",
    "\n",
    "#Build set with unique terms\n",
    "terms = set([])\n",
    "for doc in documents:\n",
    "    for term in doc:\n",
    "        if term not in terms:\n",
    "            terms.add(term)\n",
    "            \n",
    "terms = list(terms)\n",
    "\n",
    "incidence_matrix = []          #matrix elements represent terms appearing in documents\n",
    "\n",
    "for term in terms:\n",
    "    row = []\n",
    "    for doc in documents:\n",
    "        if term in doc:\n",
    "            row.append(1)\n",
    "        else:\n",
    "            row.append(0)\n",
    "    incidence_matrix.append(row)\n",
    "\n",
    "print \"---Incidence matrix---\"\n",
    "for i in incidence_matrix:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms:\n",
      "  week\n",
      "  last\n",
      "  lost\n",
      "  am\n",
      "  aggi\n",
      "  won\n",
      "  student\n",
      "  news\n",
      "  texa\n",
      "  find\n",
      "  today\n",
      "  latest\n",
      "\n",
      "\n",
      "Count_matrix:\n",
      "[0, 0, 1, 0, 0]\n",
      "[0, 0, 1, 0, 0]\n",
      "[0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[2, 1, 1, 1, 1]\n",
      "[1, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 1, 0]\n",
      "[1, 1, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "#Build term-document count matrix (tf_td)\n",
    "\n",
    "count_matrix = []\n",
    "\n",
    "print \"Terms:\"\n",
    "for i in terms:\n",
    "    print \" \", i\n",
    "    \n",
    "print \"\\n\"\n",
    "    \n",
    "\n",
    "for term in terms:\n",
    "    row = []\n",
    "    for doc in documents:\n",
    "        count = 0\n",
    "        if term in doc:\n",
    "            for index in range(0,len(doc)):\n",
    "                if doc[index] == term:\n",
    "                    count+=1\n",
    "            row.append(count)\n",
    "        else:\n",
    "            row.append(0)\n",
    "    count_matrix.append(row)\n",
    "print \"Count_matrix:\"\n",
    "for i in count_matrix:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc_frequency_vector:\n",
      "[1, 1, 1, 1, 5, 2, 1, 1, 1, 1, 2, 1] \n",
      "\n",
      "\n",
      "Tf_weighted_vector:\n",
      "0.698970004336\n",
      "0.698970004336\n",
      "0.698970004336\n",
      "0.698970004336\n",
      "0.0\n",
      "0.301029995664\n",
      "0.698970004336\n",
      "0.698970004336\n",
      "0.698970004336\n",
      "0.698970004336\n",
      "0.301029995664\n",
      "0.698970004336\n"
     ]
    }
   ],
   "source": [
    "#Build document frequency matrix\n",
    "document_freq_vec = []\n",
    "for i in range(0,len(terms)):\n",
    "    count = 0\n",
    "    for doc in documents:\n",
    "        if terms[i] in doc:\n",
    "            count+=1\n",
    "    document_freq_vec.append(count)\n",
    "    \n",
    "print \"Doc_frequency_vector:\\n\", document_freq_vec, \"\\n\\n\"\n",
    "\n",
    "#Build tf-weight vector\n",
    "N = len(documents)\n",
    "tf_weight_vec = []\n",
    "for num in document_freq_vec:\n",
    "    weight = math.log10(N/num)\n",
    "    tf_weight_vec.append(weight)\n",
    "    \n",
    "print \"Tf_weighted_vector:\"\n",
    "for i in tf_weight_vec:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Tf_idf_matrix---\n",
      "[0.0, 0.0, 0.21, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.21, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.21, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.21]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.091, 0.091, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.21]\n",
      "[0.0, 0.0, 0.0, 0.21, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.21]\n",
      "[0.0, 0.0, 0.0, 0.21, 0.0]\n",
      "[0.091, 0.091, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.21, 0.0]\n"
     ]
    }
   ],
   "source": [
    "#Build Tf-Idf Matrix\n",
    "tf_idf_matrix = []\n",
    "\n",
    "for term in range(0,len(terms)):\n",
    "    row = []\n",
    "    for doc in range(0,len(documents)):\n",
    "        weight = math.log10(1+count_matrix[term][doc])*tf_weight_vec[term]\n",
    "        row.append(round(weight,3))\n",
    "    tf_idf_matrix.append(row)\n",
    "    \n",
    "print \"---Tf_idf_matrix---\" \n",
    "for i in tf_idf_matrix:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Transpose tf_idf_matrix\n",
    "tf_idf_matrix_T = zip(*tf_idf_matrix)\n",
    "#print tf_idf_matrix_T\n",
    "\n",
    "norm_tf_idf_matrix_T = []                #normalized tf_idf_matrix transpose\n",
    "#Length Normalization\n",
    "for doc_vec in tf_idf_matrix_T:\n",
    "    #Calculate denominator\n",
    "    sum_of_squares = 0\n",
    "    for num in doc_vec:\n",
    "        sum_of_squares += num**2\n",
    "    denominator = sum_of_squares**(.5)\n",
    "    new_vec = []\n",
    "    for num in doc_vec:\n",
    "        norm_val = num / denominator\n",
    "        new_vec.append(norm_val)\n",
    "    norm_tf_idf_matrix_T.append(new_vec)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Cosine Similarity Matrix---\n",
      "[1, 1.0, 0.0, 0.0, 0.0]\n",
      "[1.0, 1, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 1, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 1, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 1]\n"
     ]
    }
   ],
   "source": [
    "#Build 5 x 5 cosine similarity matrix\n",
    "cosine_sim = []\n",
    "\n",
    "for doc_vec1 in range(0,len(norm_tf_idf_matrix_T)):\n",
    "    row = []\n",
    "    for doc_vec2 in range(0,len(norm_tf_idf_matrix_T)):\n",
    "        if doc_vec1 == doc_vec2:\n",
    "            row.append(1)\n",
    "        elif doc_vec1 < doc_vec2:                            #symmetric matrix, don't waste operations on half the mtrx\n",
    "            score = 0\n",
    "            for i in range(0,len(norm_tf_idf_matrix_T[doc_vec1])):\n",
    "                score += (norm_tf_idf_matrix_T[doc_vec1][i]*norm_tf_idf_matrix_T[doc_vec2][i])\n",
    "            row.append(round(score,4))\n",
    "        else:\n",
    "            row.append(0)\n",
    "    cosine_sim.append(row)\n",
    "    \n",
    "#Because symmetric matrix, copy over\n",
    "for doc_vec1 in range(0,len(norm_tf_idf_matrix_T)):\n",
    "    for doc_vec2 in range(0,len(norm_tf_idf_matrix_T)):\n",
    "        if doc_vec1 > doc_vec2:\n",
    "            cosine_sim[doc_vec1][doc_vec2] = cosine_sim[doc_vec2][doc_vec1]\n",
    "\n",
    "print \"---Cosine Similarity Matrix---\"\n",
    "for row in cosine_sim:\n",
    "    print row\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Part 2------------\n",
    "#Linked List Class\n",
    "class Node:\n",
    "    def __init__(self,initdata):\n",
    "        self.data = initdata\n",
    "        self.next = None\n",
    "\n",
    "    def getData(self):\n",
    "        return self.data\n",
    "\n",
    "    def getNext(self):\n",
    "        return self.next\n",
    "\n",
    "    def setData(self,newdata):\n",
    "        self.data = newdata\n",
    "\n",
    "    def setNext(self,newnext):\n",
    "        self.next = newnext\n",
    "        \n",
    "#Term & Frequency Class\n",
    "class Term:\n",
    "    def __init__(self,initterm,initfreq):\n",
    "        self.term = initterm\n",
    "        self.freq = initfreq\n",
    "        \n",
    "#Build Inverted Index\n",
    "head_container = []\n",
    "\n",
    "for row in range(0,len(incidence_matrix)):\n",
    "    count = 0\n",
    "    for i in incidence_matrix[row]:\n",
    "        count += i\n",
    "    term_data = Term(terms[row],count)   #put term and count into struct\n",
    "    node = Node(term_data)               #put struct into node\n",
    "    head_container.append(node)          #put node into head_container\n",
    "    for j in range(0,len(incidence_matrix[row])):\n",
    "        if incidence_matrix[row][j]==1:\n",
    "            temp_node = Node(j)\n",
    "            node.next=temp_node\n",
    "            node = node.next\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ week 1 ] -> 2 -> //\n",
      "\n",
      "[ last 1 ] -> 2 -> //\n",
      "\n",
      "[ lost 1 ] -> 2 -> //\n",
      "\n",
      "[ am 1 ] -> 4 -> //\n",
      "\n",
      "[ aggi 5 ] -> 0 -> 1 -> 2 -> 3 -> 4 -> //\n",
      "\n",
      "[ won 2 ] -> 0 -> 1 -> //\n",
      "\n",
      "[ student 1 ] -> 4 -> //\n",
      "\n",
      "[ news 1 ] -> 3 -> //\n",
      "\n",
      "[ texa 1 ] -> 4 -> //\n",
      "\n",
      "[ find 1 ] -> 3 -> //\n",
      "\n",
      "[ today 2 ] -> 0 -> 1 -> //\n",
      "\n",
      "[ latest 1 ] -> 3 -> //\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in head_container:\n",
    "    print \"[\", i.data.term, i.data.freq,\"] ->\",\n",
    "    node = i.next\n",
    "    while node is not None:\n",
    "        print node.data,\"->\",\n",
    "        node = node.next\n",
    "    print \"//\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
